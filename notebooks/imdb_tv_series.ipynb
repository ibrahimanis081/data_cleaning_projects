{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159232ca-6ba5-4b2b-b569-eb6e29baea9f",
   "metadata": {},
   "source": [
    "In this notebook, I will walk you through the steps to be taken to clean and carry out exploratory data analysis on the IMDB TV series data from kaggle https://www.kaggle.com/datasets/suraj520/imdb-tv-series-data\n",
    "The dataset contains information about TV series from IMDb, including details such as title, IMDb ID, release year, genre, cast, synopsis, rating, runtime, certificate, number of votes, and gross revenue. The data is scraped from the IMDb website using web scraping techniques and is organized into separate CSV files for each genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1373c-0240-45fb-9d0b-c40776af9b91",
   "metadata": {},
   "source": [
    "Importing Required Libraries:\n",
    "* glob: This library is used to retrieve file paths matching specified patterns.\n",
    "* pandas: It provides data manipulation and analysis capabilities.\n",
    "* os: This library provides a way to interact with the operating system, including file and directory operations.\n",
    "* zipfile: This library offers tools to create, read, write, and extract files from ZIP archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00270abc-953c-4e4e-a1e2-3c457ae2005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5feb6c-24d4-48f8-a3d4-97e494b0f2da",
   "metadata": {},
   "source": [
    "The imdb data is a zip file called archive.zip, to find it, you start with an empty list called zip_files to store the paths of the identified ZIP files.\n",
    "Begin walking through the directory structure using os.walk(\"/home/anees/projects/EDA_and_data_cleaning\").\n",
    "For each directory, examine the files within it.\n",
    "If a file has a \".zip\" extension, add its path to the zip_files list.\n",
    "Continue the process until all directories have been traversed.\n",
    "Finally, print the zip_files list to display the paths of all identified ZIP files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290dedd-a871-4673-839f-777dd5a37bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = []\n",
    "for root, dirs, files in os.walk(\"/home/anees/projects/EDA_and_data_cleaning\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".zip\"):\n",
    "            zip_files.append(os.path.join(root, file))\n",
    "\n",
    "print(zip_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f028389-d63a-43ac-8afc-19fabf120531",
   "metadata": {},
   "source": [
    "After obtaining the list of ZIP file paths, you will notice that the \"archive.zip\" file is located at the last index. Utilizing the zipfile library, you can extract the contents of this ZIP file to a folder named \"imdb_files\" within the \"raw_data/imdb\" directory. Once extracted, you can verify the extraction process by printing the paths of the extracted CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0520a46-ce89-45dc-8ab5-dec701979e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(zip_files[-1], \"r\") as file:\n",
    "    file.extractall(path=\"/home/anees/projects/EDA_and_data_cleaning/raw_data/imdb/imdb_files\")\n",
    "\n",
    "csv_files = glob.glob(\"/home/anees/projects/EDA_and_data_cleaning/raw_data/imdb/imdb_files/*.csv\")\n",
    "for csv_file in csv_files:\n",
    "    print(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c8257-fde2-4a93-be76-8262b6c863e7",
   "metadata": {},
   "source": [
    "To process the extracted CSV files and create a consolidated DataFrame, you can iterate through the list of CSV file paths, read each CSV file using pd.read_csv(), and append the resulting DataFrames to a list called dataframes. Finally, you can use pd.concat() to concatenate the DataFrames into a single DataFrame called imdb_df.\n",
    "By executing this code, you will obtain the consolidated DataFrame imdb_df, which contains the data from all the extracted CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b900b-0897-4795-99ea-a74ea70d344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dataframes.append(df)\n",
    "imdb_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1b45d-2a0f-498d-98bf-cf826c38b027",
   "metadata": {},
   "source": [
    "To retrieve information about the structure and summary of the consolidated DataFrame imdb_df, you can use the info() method.\n",
    "Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4003597-6bc4-4963-8f21-31654f79d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31d698-de58-4b78-a85a-8263a117593b",
   "metadata": {},
   "source": [
    "The imdb_df.info() command provides you with information about the structure and summary of the consolidated DataFrame imdb_df. \n",
    "The output provides the following details:\n",
    "* The DataFrame has a RangeIndex with 236,828 entries, ranging from index 0 to index 236,827.\n",
    "* There are 11 columns in the DataFrame.\n",
    "* Each column is listed along with its non-null count and data type.\n",
    "* The DataFrame contains a mix of data types, with 10 columns being of type object and 1 column being of type float64.\n",
    "* The memory usage of the DataFrame is reported as approximately 19.9+ MB.\n",
    "This information helps you understand the composition and structure of the DataFrame, including the number of entries, data types, and missing values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a83a45-8907-4d22-8347-db77cb3431d9",
   "metadata": {},
   "source": [
    "To enhance the DataFrame's structure, you can modify the column names to adhere to professional conventions.\n",
    "\n",
    "You can make the column names consistent by replacing any spaces with underscores (_) and converting them to lowercase. You can then use the info() method again to verify the changes have been effected\n",
    "\n",
    "Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc83a3-8856-4103-87d0-b5b044caa1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.columns = imdb_df.columns.str.replace(' ', '_').str.lower()\n",
    "imdb_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee5da6-e68e-44a6-b9be-f37b003bcaf2",
   "metadata": {},
   "source": [
    "To preview the data in the DataFrame, you can use the head() and tail(), and sample() methods. By defualt the head() method shows the top 5 rows of the DataFrame, the tail() method shows the bottom 5 rows and sample() method returns a single random row from the DataFrame. These methods can take an argument specifying the number of rows to be returned.\n",
    "For example, imdb_df.head(10) will display the top 10 rows, imdb_df.tail(3) will display the last 3 rows and imdb_df.sample(6) randomly selects and returns 6 rows from the DataFrame.\n",
    "\n",
    "By utilizing these methods, you can preview the data in the DataFrame and get a sense of its contents and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0dade9-5825-41c5-ac84-984d9047093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759c0b6-9a66-49b4-ade7-164de952bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad6649-4d41-4019-bf7c-92a2db3f71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567ffae-1403-4c26-ba3d-5d144e48773e",
   "metadata": {},
   "source": [
    "One thing you have to decide very early on in a data cleaning and EDA process is identify your index column, an index column provides labels or names for the rows in the DataFrame. It allows you to uniquely identify and access specific rows based on their index values. If you don't specify an index column, pandas assigns a default integer index starting from 0. However, setting a meaningful and appropriate index can enhance data analysis and manipulation capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51372a3-f2fc-463c-b488-024243582ab2",
   "metadata": {},
   "source": [
    "Looking at the output of the info, head, tail and sample methods, one colunm that looks like it can be use as an index column is imdb_id column, lets explore further. to see the content of the column, use the the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd92f2d-c966-4541-8cbb-f9d212beb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[\"imdb_id\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e9ad0e-2f57-43f2-b073-31b3b9fab777",
   "metadata": {},
   "source": [
    "also since you want the column to uniqely identify each row in the dataframe, you have to check and make sure there is no duplicate value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44763b39-fdc4-4d3b-aa60-1630387285ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[\"imdb_id\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b1830-b03d-4ef9-b0fd-76f86081009d",
   "metadata": {},
   "source": [
    "there are 127631 duplicate values in the column, you con confirm if they are actual duplicates or if the same imdb_id is associated to different records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94dc80-f181-49a8-882d-d1752c9ca275",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.head(100).duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c45235-dd75-4e1d-aa5a-d7595a8737c1",
   "metadata": {},
   "source": [
    "using the head method to select the first 100 rows shows no duplicates, lets use the tail method instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd377d4-05b2-4220-82b3-ae06bcd7f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.tail(100).duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d30cd-5234-40a7-bb67-57137e786658",
   "metadata": {},
   "source": [
    "the tail method in the other hand shows a couple of records are duplicated, selct the last record on the dataframe using the iloc method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec3479-218b-4c41-b498-8dc92721ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row = imdb_df.iloc[-1]\n",
    "print(last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12471067-67b1-4fb2-a6fc-d3cf51b331ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[imdb_df[\"title\"] == \"Evil Dead\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff9e42-cadd-451a-a42a-19d289213808",
   "metadata": {},
   "source": [
    "from the result, we can see that they are actual duplicate, to be safe, lets check for another row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c603e-8d6b-49a2-8657-f4a3f5b5beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_last_row = imdb_df.iloc[-2]\n",
    "print(second_last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d954d2-84f3-46aa-aa21-8c41a474b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[imdb_df[\"title\"] == 'Scream']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62387409-aba7-4e86-b06e-ab893403541f",
   "metadata": {},
   "source": [
    "even though there are multiple movies with the title scream, they all have different imdb_id, so we can conclude that each imdb_id is associated with only one unique record. Now we can safely drop any duplicate record in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c86719-fa05-4383-9660-854cf94475da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = imdb_df.drop_duplicates(subset=\"imdb_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815c44a-a969-44d4-ab61-046402a266d2",
   "metadata": {},
   "source": [
    "you then verify if the duplicates have been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4fd0d-0114-421d-9f60-92914b2aca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[\"imdb_id\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30db108-ca76-4950-a0bf-3aad9728c4c4",
   "metadata": {},
   "source": [
    "this time around, you got zero, meaning there are no duplicate value in the column. now we can safely use the imdb_id column as our index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6078c4-398b-4daf-aaf7-dfdbaf836ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.set_index(\"imdb_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60695dc-2ec6-4a6c-8ee8-a07211482e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20138a2-89bb-4c40-999f-1941248bcb8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e22c1-8854-42be-99a5-7664e893e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_df[\"title\"].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9c55a-8b46-4478-aa51-cfad74a8d72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec5b2684-0e25-4433-a34f-da0857d061c9",
   "metadata": {},
   "source": [
    "Something else you might have noticed is that the release_year column contain charcaters that are notthe release_year column should contain only four digit, signifying a year but as you can see, we have cases of special charcaters (braces and dash), and a case of the roman numeral \"I\" making an appearence \n",
    "To gain a comprehensive understanding of the cleanliness of the \"release_year\" column, you can identify several issues by examining its unique values.\n",
    "To obtain a clear picture of the unique values in the column and address these concerns, we can assign the unique values to a variable and print them. Here's the code to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51149b44-7295-4cea-9934-5f03273c8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = imdb_df['release_year'].unique()\n",
    "#print(unique_values)\n",
    "#optionally, you can loop through the list object and print out each unique value\n",
    "for value in unique_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71bf29-610a-41a2-8f5b-5e78829b92c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72968b20-59eb-4a35-8d60-9b628eac4d04",
   "metadata": {},
   "source": [
    "When addressing the task of cleaning the release_year column, you have two viable approaches. The first option entails directly cleaning the column itself, while the second option involves cleaning the unique_values and subsequently replacing the release_year column with the cleaned list.\n",
    "\n",
    "The choice between these options largely depends on the specific requirements and constraints of the data analysis task at hand. Cleaning the column directly allows for immediate modifications within the DataFrame, which can be advantageous when there is a need to retain the original structure and integrity of the dataset. Conversely, opting to clean the unique_values list independently can offer the advantage of decoupling the cleaning process from the DataFrame, facilitating analysis and transformations on a reduced and sanitized dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb976e-d010-4781-b989-6fed8beb4b51",
   "metadata": {},
   "source": [
    "We will be going with the first approach, you can opt for the second one if you like.\n",
    "\n",
    "You can clean the 'release_year' column by removing all characters that are not digits. The following code accomplishes this\n",
    "The code uses the str.replace() method with the regular expression pattern r'[^\\d]' to match any character that is not a digit. The regex=True parameter ensures that the replacement is performed using regular expressions. By replacing the matched characters with an empty string, you effectively remove all non-digit characters from the 'release_year' column.\n",
    "\n",
    "After executing the code, the 'release_year' column will only contain the cleaned numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c50f11-9dd0-4a2c-ae66-154ac23f378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['release_year'] = imdb_df['release_year'].str.replace(r'[^\\d]', '', regex=True)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb9d83-6f86-4c36-b9c9-1ded45d75c16",
   "metadata": {},
   "source": [
    "The resulting 'release_year' column is expected to display cleaned numerical values upon executing the code.\n",
    "However, it is important to note that the 'release_year' column may still exhibit an issue as identified when inspecting the tail of the DataFrame. The removal of non-digit characters inadvertently eliminated the separator (-) that differentiates the two years in some entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093bbfd-80aa-4cc4-9aa8-0b969f00be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506467d-195b-4526-8b60-7cd1bced5447",
   "metadata": {},
   "source": [
    "To address this problem, you can use regular expressions to insert the hyphen at the desired position. Here's an example:\n",
    "In the following code, we use the str.replace() method with a regular expression pattern (\\d{4})(\\d{4}) to match the string of eight digits representing two years. The pattern captures the first four digits and the next four digits separately. Then, we replace the match with \\1-\\2, which inserts a hyphen '-' between the two captured groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554c1dc-f7e0-4a1a-9a6f-99b6a3f5abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['release_year'] = imdb_df['release_year'].str.replace(r'(\\d{4})(\\d{4})', r'\\1-\\2', regex=True)\n",
    "imdb_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3d480-bc02-4ce4-b158-859706856b4d",
   "metadata": {},
   "source": [
    "You can proceed to drop any columns that are not relevant to your analysis. For example, if you are not interested in the imdb_id or the synopsis of each movie, you can drop those columns using code block below.\n",
    "The code block drops the imdb_id and synopsis columns from the imdb_df DataFrame. The axis=1 argument tells Pandas to drop the columns along the column axis. The inplace=True argument tells Pandas to modify the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eba634-cba4-4feb-93d5-8be0b3fa3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.drop([\"imdb_id\", \"synopsis\"], axis = 1, inplace = True)\n",
    "imdb_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799880d-f020-4086-93be-26728a214bba",
   "metadata": {},
   "source": [
    "Moving on, you can check for the total number of duplicate values in the dataframe with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69003ebf-3c92-49ac-b339-b4947650f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6a24b25-4c89-4f63-9546-0b85c00c8c5a",
   "metadata": {},
   "source": [
    "this information in itself is not that useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c2c95-18c4-446a-9086-3f5dc0a32b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58feb03-59b2-418a-82ee-d88dd0f69dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b52e8-906f-4baf-b267-594baa3fb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df[imdb_df['title'] == \"Boys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64311bce-a9ca-4dc6-9d39-3e1a24a23125",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
